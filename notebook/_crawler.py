# -*- coding: utf-8 -*-
"""crawler.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1etfm7kTpxeKWn7GRAB4WE_RrVGXNgeOP

```
# This is formatted as code
```

# Crawler written by Quentin
"""

from bs4 import BeautifulSoup
from urllib.request import urlopen
import csv

f = open(file='CollectedData.csv', mode='w', encoding='utf-8-sig')
writer = csv.writer(f)
with open('Dataset_EN.csv', 'rt', newline='') as csvfile:
  reader = csv.reader(csvfile)
  column = [row[7] for row in reader]


'''testing: use a smaller range '''
for url in range(1,5):

  html = urlopen(column[url])
  soup = BeautifulSoup(html.read())
  for x in range(22):
      writer.writerow([soup.select("td")[x].get_text()])
f.close()
csvfile.close()

!pip install scrapy
import scrapy

''' The below is added by Robbin '''
import re

with open('Dataset_EN.csv', 'rt', newline='') as csvfile:
  reader = csv.reader(csvfile)
  for row in reader:
    ExtractedURL = re.escape(row[7])